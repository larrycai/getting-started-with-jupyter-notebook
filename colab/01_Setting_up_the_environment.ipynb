{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Setting_up_the_environment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ7R94San8Fk"
      },
      "source": [
        "# Milestone 1\n",
        "## Setting up the environment\n",
        "\n",
        "### Pythagorean theorem\n",
        "The theorem says: $a^2+b^2=c^2$. We'd like to implement a function which computes the hypotenuse given the adjacent and the opposite. So, the function\n",
        "will compute $c=\\sqrt{a^2 + b^2}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgYBtbenuFu"
      },
      "source": [
        "def pythagorean(a,b):\n",
        "  import math\n",
        "  \"\"\"Given the adjacent and the opposite, returns the hypotenuse\n",
        "  Args:\n",
        "    a (int): the adjacent\n",
        "    b (int): the opposite\n",
        "\n",
        "  Returns:\n",
        "    int: the opposite\n",
        "  \"\"\"\n",
        "  return math.sqrt((a**2) + (b**2))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQkmMv3fpCqP"
      },
      "source": [
        "And let's try out the function with a few arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhALD59pI76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ba6daf-28cb-4180-d107-a2323187899e"
      },
      "source": [
        "print(pythagorean(1,1))\n",
        "print(pythagorean(2,1))\n",
        "print(pythagorean(2,2))\n",
        "print(pythagorean(2,10))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4142135623730951\n",
            "2.23606797749979\n",
            "2.8284271247461903\n",
            "10.198039027185569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtsMAXZKx6-h"
      },
      "source": [
        "# Naive Bayes\n",
        "We will train a [Multinomial Naive Bayes](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/) classifier on the SMS Spam Collection using scikit learn.\n",
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfCvf9NfzfCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69c7a13-38ef-465d-c48e-3ace0afe9037"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdwQRPcQWGb_",
        "outputId": "f3a88b9f-8ec6-42b4-dbf1-97238f2662e0"
      },
      "source": [
        "# check the folder is mounted, \r\n",
        "# http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/ for SMS data\r\n",
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "mypath=\"/content/drive/My Drive/Colab Notebooks/01_models\"\r\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\r\n",
        "print(onlyfiles)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_arNPcDzpxj"
      },
      "source": [
        "You can access your folder with the prefix \"/content/drive/My Drive/\".\n",
        "## Scikit-learn GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV2YBQ0Vx9kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89051784-2246-4c74-b7f0-6d1850f9d98f"
      },
      "source": [
        "import pickle\n",
        "import string\n",
        "\n",
        "from joblib import dump, load\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load raw data\n",
        "texts = []\n",
        "labels = []\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/01_data/SMSSpamCollection.txt\", \"r\") as infile:\n",
        "  for l in infile:\n",
        "    label, text = l.strip().split(\"\\t\")\n",
        "    labels.append(label)\n",
        "    text = \"\".join([ch.lower() for ch in text if ch not in string.punctuation])\n",
        "    texts.append(text)\n",
        "\n",
        "# train-test split\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(texts, labels, random_state=42)\n",
        "\n",
        "# vectorize training and test\n",
        "vectorizer = CountVectorizer() # only training vocab counts!\n",
        "X_train = vectorizer.fit_transform(X_train_raw)\n",
        "vctrzr = CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
        "X_test = vctrzr.fit_transform(X_test_raw)\n",
        "\n",
        "to_be_saved = [X_train, X_test, y_train, y_test]\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/01_data/vectorized_data.p\", \"wb\") as outfile:\n",
        "  pickle.dump(to_be_saved, outfile)\n",
        "\n",
        "# train MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "dump(clf, \"/content/drive/My Drive/Colab Notebooks/01_models/NB.joblib\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/01_models/NB.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy7hZG0RazI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a50917-dd3b-4e85-9d32-a6ebaad415b0"
      },
      "source": [
        "print(len(X_train.toarray()[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wNfZfZrazH0"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysk5pVVV0O52"
      },
      "source": [
        "## Load & evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDTAalV40Scr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e169e37e-9a26-4f80-8c4a-30e2b737d587"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf = load(\"/content/drive/My Drive/Colab Notebooks/01_models/NB.joblib\")\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99      1203\n",
            "        spam       0.97      0.92      0.95       191\n",
            "\n",
            "    accuracy                           0.99      1394\n",
            "   macro avg       0.98      0.96      0.97      1394\n",
            "weighted avg       0.99      0.99      0.99      1394\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDhtMDEILGCC"
      },
      "source": [
        "Now, we are ready to move on to Milestone 2."
      ]
    }
  ]
}